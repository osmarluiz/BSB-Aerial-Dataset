{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT LIBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image, ImageDraw\n",
    "from pathlib import Path\n",
    "import torch, torchvision\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "import glob\n",
    "import imageio\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "ROOT_DIR = 'F:/detectron2/'\n",
    "assert os.path.exists(ROOT_DIR)\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor,default_argument_parser, default_setup, launch\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator, COCOPanopticEvaluator, DatasetEvaluators, SemSegEvaluator\n",
    "from detectron2.data.datasets import register_coco_panoptic_separated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REGISTER DATASET\n",
    "- register_coco_panoptic\n",
    "- register_coco_panoptic_separated\n",
    "\n",
    "Here, you just need to update the paths to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_coco_panoptic_separated(name=\"train\",\n",
    "                                 metadata={},\n",
    "                                 image_root=\"F:/detectron2/datasets/bsb_dataset/image_train\",\n",
    "                                 panoptic_root=\"F:/detectron2/datasets/bsb_dataset/panoptic_train\",\n",
    "                                 sem_seg_root=\"F:/detectron2/datasets/bsb_dataset/panoptic_stuff_train\",\n",
    "                                 panoptic_json=\"F:/detectron2/datasets/bsb_dataset/annotations/panoptic_train.json\",\n",
    "                                 instances_json=\"F:/detectron2/datasets/bsb_dataset/annotations/instance_train.json\")\n",
    "\n",
    "register_coco_panoptic_separated(name=\"val\",\n",
    "                                 metadata={},\n",
    "                                 image_root=\"F:/detectron2/datasets/bsb_dataset/image_val\",\n",
    "                                 panoptic_root=\"F:/detectron2/datasets/bsb_dataset/panoptic_val\",\n",
    "                                 sem_seg_root=\"F:/detectron2/datasets/bsb_dataset/panoptic_stuff_val\",\n",
    "                                 panoptic_json=\"F:/detectron2/datasets/bsb_dataset/annotations/panoptic_val.json\",\n",
    "                                 instances_json=\"F:/detectron2/datasets/bsb_dataset/annotations/instance_val.json\")\n",
    "\n",
    "\n",
    "register_coco_panoptic_separated(name=\"test\",\n",
    "                                 metadata={},\n",
    "                                 image_root=\"F:/detectron2/datasets/bsb_dataset/image_test\",\n",
    "                                 panoptic_root=\"F:/detectron2/datasets/bsb_dataset/panoptic_test\",\n",
    "                                 sem_seg_root=\"F:/detectron2/datasets/bsb_dataset/panoptic_stuff_test\",\n",
    "                                 panoptic_json=\"F:/detectron2/datasets/bsb_dataset/annotations/panoptic_test.json\",\n",
    "                                 instances_json=\"F:/detectron2/datasets/bsb_dataset/annotations/instance_test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_metadata = MetadataCatalog.get(\"train_separated\")\n",
    "dataset_dicts = DatasetCatalog.get(\"train_separated\")\n",
    "\n",
    "city_metadata_val = MetadataCatalog.get('val_separated')\n",
    "dataset_dicts_val = DatasetCatalog.get('val_separated')\n",
    "\n",
    "city_metadata_test = MetadataCatalog.get('test_separated')\n",
    "dataset_dicts_test = DatasetCatalog.get('test_separated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetadataCatalog.get(\"train_separated\").set(stuff_classes=['',\n",
    "                                                          'street',\n",
    "                                                          'permeable area',\n",
    "                                                          'lake'])\n",
    "\n",
    "MetadataCatalog.get(\"train_separated\").set(thing_classes=['swimming pool',\n",
    "                                                          'harbor',\n",
    "                                                          'vehicle',\n",
    "                                                          'boat',\n",
    "                                                          'sports court',\n",
    "                                                          'soccer field',\n",
    "                                                          'comm. building',\n",
    "                                                          'comm. building block',\n",
    "                                                          'res. building',\n",
    "                                                          'house',\n",
    "                                                          'small construction'])\n",
    "\n",
    "MetadataCatalog.get(\"train_separated\").set(stuff_dataset_id_to_contiguous_id={0: 0,\n",
    "                                                                              1: 1,\n",
    "                                                                              2: 2,\n",
    "                                                                              3: 3})\n",
    "\n",
    "MetadataCatalog.get(\"train_separated\").set(thing_dataset_id_to_contiguous_id={4: 0,\n",
    "                                                                              5: 1,\n",
    "                                                                              6: 2,\n",
    "                                                                              7: 3,\n",
    "                                                                              8: 4,\n",
    "                                                                              9: 5,\n",
    "                                                                              10: 6,\n",
    "                                                                              11: 7,\n",
    "                                                                              12: 8,\n",
    "                                                                              13: 9,\n",
    "                                                                              14: 10})\n",
    "\n",
    "MetadataCatalog.get(\"train_separated\").stuff_colors = [(0,0,0), (128,128,128), (0,128,0), (200,0,0)]\n",
    "\n",
    "#val\n",
    "MetadataCatalog.get(\"val_separated\").set(stuff_classes=['',\n",
    "                                                        'street',\n",
    "                                                        'permeable area',\n",
    "                                                        'lake'])\n",
    "\n",
    "MetadataCatalog.get(\"val_separated\").set(thing_classes=['swimming pool',\n",
    "                                                        'harbor',\n",
    "                                                        'vehicle',\n",
    "                                                        'boat',\n",
    "                                                        'sports court',\n",
    "                                                        'soccer field',\n",
    "                                                        'comm. building',\n",
    "                                                        'comm. building block',\n",
    "                                                        'res. building',\n",
    "                                                        'house',\n",
    "                                                        'small construction'])\n",
    "\n",
    "MetadataCatalog.get(\"val_separated\").set(stuff_dataset_id_to_contiguous_id={0: 0,\n",
    "                                                                            1: 1,\n",
    "                                                                            2: 2,\n",
    "                                                                            3: 3})\n",
    "\n",
    "MetadataCatalog.get(\"val_separated\").set(thing_dataset_id_to_contiguous_id={4: 0,\n",
    "                                                                            5: 1,\n",
    "                                                                            6: 2,\n",
    "                                                                            7: 3,\n",
    "                                                                            8: 4,\n",
    "                                                                            9: 5,\n",
    "                                                                            10: 6,\n",
    "                                                                            11: 7,\n",
    "                                                                            12: 8,\n",
    "                                                                            13: 9,\n",
    "                                                                            14: 10})\n",
    "\n",
    "MetadataCatalog.get(\"val_separated\").stuff_colors = [(0,0,0), (128,128,128), (0,128,0), (200,0,0)]\n",
    "\n",
    "#test\n",
    "MetadataCatalog.get(\"test_separated\").set(stuff_classes=['',\n",
    "                                                        'street',\n",
    "                                                        'permeable area',\n",
    "                                                        'lake'])\n",
    "\n",
    "MetadataCatalog.get(\"test_separated\").set(thing_classes=['swimming pool',\n",
    "                                                        'harbor',\n",
    "                                                        'vehicle',\n",
    "                                                        'boat',\n",
    "                                                        'sports court',\n",
    "                                                        'soccer field',\n",
    "                                                        'comm. building',\n",
    "                                                        'comm. building block',\n",
    "                                                        'res. building',\n",
    "                                                        'house',\n",
    "                                                        'small construction'])\n",
    "\n",
    "MetadataCatalog.get(\"test_separated\").set(stuff_dataset_id_to_contiguous_id={0: 0,\n",
    "                                                                            1: 1,\n",
    "                                                                            2: 2,\n",
    "                                                                            3: 3})\n",
    "\n",
    "MetadataCatalog.get(\"test_separated\").set(thing_dataset_id_to_contiguous_id={4: 0,\n",
    "                                                                            5: 1,\n",
    "                                                                            6: 2,\n",
    "                                                                            7: 3,\n",
    "                                                                            8: 4,\n",
    "                                                                            9: 5,\n",
    "                                                                            10: 6,\n",
    "                                                                            11: 7,\n",
    "                                                                            12: 8,\n",
    "                                                                            13: 9,\n",
    "                                                                            14: 10})\n",
    "MetadataCatalog.get(\"test_separated\").stuff_colors = [(0,0,0), (128,128,128), (0,128,0), (200,0,0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHOW IMAGES & ANNOTATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHOW SINGLE IMAGE WITH ANNOTATION\n",
    "- This shows an example on how to show a given image from the dataset and its corresponding panoptic annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose image number\n",
    "img_number = 21\n",
    "\n",
    "img_path = 'F:/detectron2/datasets/bsb_dataset/image_test/' + str(img_number) + '.tiff'\n",
    "image = imageio.imread(img_path)\n",
    "    \n",
    "img_copy = image.copy()\n",
    "visualizer = Visualizer(img_copy, metadata=city_metadata_test, scale=1)\n",
    "vis = visualizer.draw_dataset_dict(dataset_dicts_test[img_number])\n",
    "    \n",
    "NUM_ROWS = 1\n",
    "IMGs_IN_ROW = 2\n",
    "f, ax = plt.subplots(NUM_ROWS, IMGs_IN_ROW, figsize=(20,20))\n",
    "    \n",
    "ax[0].imshow(img_copy/300)\n",
    "ax[1].imshow(vis.get_image()[:, :, ::-1])\n",
    "\n",
    "ax[0].set_title('Original image | '+str(img_number))\n",
    "ax[1].set_title('Panoptic Annotation | '+str(img_number))\n",
    "\n",
    "print('ID:'+str(img_number+1))\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHOW MANY IMAGES WITH ANNOTATIONS\n",
    "- This shows an example on how to show many images at a time using a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for img_number in range(0, 100):\n",
    "    \n",
    "    img_path = 'F:/detectron2/datasets/bsb_dataset/image_val/' + str(img_number+1) + '.tiff'\n",
    "    image = imageio.imread(img_path)\n",
    "    \n",
    "    img_copy = image.copy()\n",
    "    visualizer = Visualizer(img_copy, metadata=city_metadata_val, scale=0.9)\n",
    "    vis = visualizer.draw_dataset_dict(dataset_dicts_val[img_number])\n",
    "    \n",
    "    NUM_ROWS = 1\n",
    "    IMGs_IN_ROW = 2\n",
    "    f, ax = plt.subplots(NUM_ROWS, IMGs_IN_ROW, figsize=(20,20))\n",
    "    \n",
    "    ax[0].imshow(img_copy/300)\n",
    "    ax[1].imshow(vis.get_image()[:, :, ::-1])\n",
    "\n",
    "    ax[0].set_title('Original image | '+str(img_number+1))\n",
    "    ax[1].set_title('Panoptic Annotation | '+str(img_number+1))\n",
    "\n",
    "    print('ID:'+str(img_number+1))\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Trainer\n",
    "- Please read the Detectron2 Trainer documentation if you wish to have more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
    "        evaluator_list = []\n",
    "        evaluator_type = MetadataCatalog.get(dataset_name).evaluator_type\n",
    "\n",
    "        evaluator_list.append(COCOEvaluator(dataset_name, cfg, True, output_folder))\n",
    "        evaluator_list.append(COCOPanopticEvaluator(dataset_name, output_folder))\n",
    "        evaluator_list.append(SemSegEvaluator(dataset_name, distributed=True, output_dir=output_folder))\n",
    "        \n",
    "        if len(evaluator_list) == 0:\n",
    "            raise NotImplementedError(\n",
    "                \"no Evaluator for the dataset {} with the type {}\".format(\n",
    "                    dataset_name, evaluator_type\n",
    "                )\n",
    "            )\n",
    "        elif len(evaluator_list) == 1:\n",
    "            return evaluator_list[0]\n",
    "            \n",
    "        return DatasetEvaluators(evaluator_list)\n",
    "\n",
    "    @classmethod\n",
    "    def test_with_TTA(cls, cfg, model):\n",
    "        logger = logging.getLogger(\"detectron2.trainer\")\n",
    "        # In the end of training, run an evaluation with TTA\n",
    "        # Only support some R-CNN models.\n",
    "        logger.info(\"Running inference with test-time augmentation ...\")\n",
    "        model = GeneralizedRCNNWithTTA(cfg, model)\n",
    "        evaluators = [\n",
    "            cls.build_evaluator(\n",
    "                cfg, name, output_folder=os.path.join(cfg.OUTPUT_DIR, \"inference_TTA\")\n",
    "            )\n",
    "            for name in cfg.DATASETS.TEST\n",
    "        ]\n",
    "        res = cls.test(cfg, model, evaluators)\n",
    "        res = OrderedDict({k + \"_TTA\": v for k, v in res.items()})\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "cfg = get_cfg()\n",
    "\n",
    "# Choose model\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml\"))\n",
    "\n",
    "cfg.DATASETS.TRAIN = (\"train_separated\",)\n",
    "cfg.DATASETS.TEST = (\"test_separated\",)\n",
    "\n",
    "cfg.DATALOADER.NUM_WORKERS = 0\n",
    "\n",
    "# Number of images per batch\n",
    "cfg.SOLVER.IMS_PER_BATCH = 1\n",
    "\n",
    "# Learning Rate\n",
    "cfg.SOLVER.BASE_LR = 0.00005\n",
    "\n",
    "# Number of epochs\n",
    "cfg.SOLVER.MAX_ITER = 1 #1000\n",
    "\n",
    "cfg.BATCH_SIZE_PER_IMAGE = 512\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 11 # number of classes\n",
    "cfg.MODEL.SEM_SEG_HEAD.NUM_CLASSES = 4\n",
    "\n",
    "cfg.MODEL.BACKBONE.FREEZE_AT = 4\n",
    "\n",
    "cfg.TEST.EVAL_PERIOD = 1000 #2500\n",
    "\n",
    "# Load pre trained weights\n",
    "#cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-PanopticSegmentation/panoptic_fpn_R_50_3x.yaml\")\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_best.pth\")\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "#trainer = DefaultTrainer(cfg)\n",
    "trainer = Trainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFERENCE ON IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_number = 53\n",
    "\n",
    "img_path = 'F:/detectron2/datasets/bsb_dataset/image_val/' + str(img_number) + '.tiff'\n",
    "image = imageio.imread(img_path)\n",
    "\n",
    "#cfg = get_cfg()\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0\n",
    "predictor = DefaultPredictor(cfg)\n",
    "panoptic_seg, segments_info = predictor(image)[\"panoptic_seg\"]\n",
    "v = Visualizer(image[:, :, ::-1], metadata=city_metadata_test, scale=1)\n",
    "out = v.draw_panoptic_seg_predictions(panoptic_seg.to(\"cpu\"), segments_info)\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.axis('off')\n",
    "\n",
    "plt.imshow(out.get_image()[:, :, ::-1])\n",
    "\n",
    "#uncomment below to save image\n",
    "#plt.savefig('imgs/val_' + str(img_number) + '.png', dpi=400,  bbox_inches='tight', pad_inches=0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
